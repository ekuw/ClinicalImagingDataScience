\documentclass{article}

\usepackage[margin=1.0in]{geometry}
\usepackage{authblk}
\usepackage{url}
\usepackage[sorting=none]{biblatex}
\addbibresource{data-hazards.bib}


\title{Stroke Imaging And Clinical Database For Artificial
  Intelligence: Data Hazards
  Workshop Report}
\author{Emma Si\^{a}n Kuwertz}
\affil{Jean Golding Institute, University of Bristol}
\date{2021}

\begin{document}
\maketitle
%\tableofcontents
\section{Introduction}

Stroke is a major cause of disability in adults. Treatment
decisions rely on the ability of clinicians to combine insights
gleaned from medical imaging (e.g. computerized tomography (CT)) with
relevant clinical information and patient medical histories to anticipate the outcome of different treatment
scenarios. Decision support tools exist, but these are typically able
to consider information from isolated sources and do not allow the
integration of medical images. The \textit{Stroke Imaging and Clinical
Database for AI} project aims to extract provide a linked dataset,
using clinical and medical imaging inputs from North Bristol Trust (NBT). 
This will facilitate the development of multi-modal models to explore the potential for stroke treatment outcome
prediction.\\

This project includes patient information collected at NBT as a part
of routine care. Public patient involvement (PPI) is an essential
requirement of this research, and helps to ensure that the project
will be designed and implemented in such a way as to be acceptable to
the public. Community engagement also enhances the ethical
review process, facilitating open discussions about the risks and
benefits of the research and potentially flagging issues that can be
addressed early on in the project development.\\

As a part of internal ethics review and public consultation, this
project was presented and discussed at the first \textit{Data Hazards
  Workshop}~\cite{data-hazards-workshop}.
This article reports on the project-specific discussions from that
workshop and summarises the feedback from the community.

\section{Data Hazards}
\label{sec:data-labels}
The idea underpinning data hazards~\cite{data-hazards} is that the ethical implications of
research projects are often broad and can evolve as projects
develop and even after public release (depending on subsequent
use-cases). Given this, a standard vocabulary for potential ethical
concerns can as a mechanism
to prompt reflection within research teams during project planning and
execution and to
label research outputs to indicate potential ethical pitfalls that should be
considered when using them. \\

The data hazard labels used to stimulate discussion in this exercise
are as follows:

\begin{itemize}
\item \textbf{Reinforces existing biases:} Applies to technologies
  that could reinforce discriminatory biases as a consequence of data
  composition or other design choices. 
\item \textbf{Ranks or classifies people:} Applies to technologies
  that might categorize or rank individuals.
\item \textbf{High environmental cost:} Applies to assets that are
  large energy consumers, or require rare or environmentally
  compromising materials.
\item \textbf{Lacks community involvement:} Applies where the dataset
  or algorithm is being developed without involvement or engagement of
  the community that it is designed to benefit.
\item \textbf{Danger of misuse:} Applies where there is a risk that the dataset or
  algorithm could be used for purposes contrary to its
  design principles in a potentially negative way. 
\item \textbf{Difficult to understand:} Applies where the output from
  the dataset or algorithm is difficult to interpret, or the process
  to followed to obtain the output is difficult to understand or unavailable.
\item \textbf{May cause direct harm:} Applies where direct physical or
  psychological harm may be caused to a person as a consequence of the
  dataset or algorithm when the technology or asset is being applied
  in its intended way.
\item \textbf{Privacy:} Applies where there may be a risk to the
  privacy of those whose data contributes to or is processed by the
  dataset or algorithm. 
\item \textbf{Automates decision making:} Applies where decision
  making is automated.
\item \textbf{Lacks informed consent:} Applies where a dataset or
  algorithm makes use of data without explicit consent of the data
  owner or creator.
\end{itemize}

\section{Workshop format and participation}

The primary aim of this workshop was to get community feedback from
researchers and professionals working in data analytics on the concept
of data hazard labels.
Participants were introduced to the idea of data hazards and data
hazard labels in a plenary session, which included a research project
walk-through. Here, an example research project was presented to the
group, and the data labels that the project owner had identified as
applicable to the work were shown and explained.
Next, the group was separated into groups of participants, one
facilitator and one project owner.
In these groups, the project owner introduces their research project
in a 5 minute presentation. Following this, the participants can ask
the project owner questions about the project. These questions should
be asked with the purpose of clarifying facts about the project,
rather than seeking the opinion of the project owner.
Participants are then asked to determine which of the data hazards
listed in Section~\ref{sec:data-labels} they feel apply to the
project. The participants then discuss their choices as a group,
explaining their thought processes for each relevant data hazard.
The project owner listens without comment and is able to take note of
the discussion themes and any specific points to consider further in
the project development. All participants are finally brought out of
their groups back into the plenary room, where feedback on the concept
of data hazard labels is collected. \\

The \textit{Stroke Imaging and Clinical Database for AI} project was
presented to one of the break-out groups in the data hazards workshop.
There were five participants in the discussion group:

\begin{itemize}
\item PhD student in environmental economics.
\item PhD student in mental health data science.
\item Lecturer, machine translation.
\item Medical data manager.
\item Data scientist, Foreign, Commonwealth and Development Office.
\end{itemize}


\section{Discussion}

In this section the views expressed by workshop participants in
relating data hazard labels to the \textit{Stroke Imaging and Clinical
  Database for AI} project are summarised. These are then reflected
upon and avenues for mitigation of identified hazards are discussed.


\subsection{Participant feedback}

During the discussion of this project it was noted that in general it
is difficult to eliminate any of the data hazards listed in
Section~\ref{sec:data-labels} entirely. Given that ``\textit{anything}
can be misused in principle,'' there was a question as to whether,
under misuse, \textit{all} of the data hazards could subsequently apply (even
if they were not assigned in the original assessment of the project in
its current scope).
The discussion group agreed that they would focus on assessing and
applying hazard labels to the concept of a research data repository,
while also considering how that resource might be used in the
future. The discussions relating to the hazards which were identified
most frequently are summarised in the following dedicated sections. 

\subsubsection{Reinforcing existing biases}
There were some concerns that the research database could reinforce
existing biases. With the data being
extracted from NBT only, and with a focus on patients undergoing
neuro-imaging procedures, the dataset is likely to preferentially
include certain demographics. Participants argued that without understanding the composition of
the sample, and being able to draw in other datasets to offset
any identifiable selection bias, it is difficult to imagine that there
wouldn't be some selection bias in the data. It should also be noted
that data collected from NBT might not be representative of data in
other trusts nationally. For example, when and how
illnesses are reported could differ systematically.
It was acknowledged that it is difficult to assess what potential
biases could exist in the data without having subject-specialist
knowledge. It was felt that knowing what information
exactly might be considered most important for clinical decision
making would make it easier to consider and identify potential biases
in the data, and how relying on that data for algorithmic development
could reinforce those biases. \\ 

  
\subsubsection{Danger of misuse}

Given that the project involves a dataset, rather than an algorithm,
as an output, participants expressed difficulty in
predicting all possible future uses. One participant noted that,
because the range of applications is so broad, it is hard to
anticipate what forms of misuse could arise if the dataset were made
openly available. There was still open speculation, with one
participant citing research linking intelligence to brain
images~\cite{dubois}. Through this worst-case-scenario discussion,
one participant pointed out that open data is often an important and
fruitful resource that helps researchers better understand societal,
environmental and medical issues. While they acknowledged the
necessity for ethical oversight, they felt that sometimes considering
worst-case-scenarios can lead people to the conclusion that publishing data
is ``dangerous and we shouldn't do it.'' They felt that potential
benefits to society should be considered alongside risk to strike a
balance. 

\subsubsection{Lack of informed consent}

It was generally accepted that, since the database would contain
patient data collected as a part of routine care (extending across
over a decade), the exercise of
acquiring project-specific consent for processing that data would be
challenging. Despite the acknowledgment that patients are aware that
their personal data are being collected in a medical setting, there
were questions around whether people can really understand what
happens to their data and what it could be subsequently used for.
One participant expressed that in their experience people generally
assumed that their health-related data would be used to further
health care practice and operations.


\subsubsection{Lacks community involvement}

Participants were keen that there be adequate consultation with
patients to understand their views on this project. This was felt to
be of particular importance given the absence of dedicated consent
from the patients whose data would contribute to the research
database. 

Patient consultation is important -- should do this as a part of
  the study (PPI).  
 Patients generally support data use for benefit of society.

\subsection{Reflection and mitigation}
 
The discussion surrounding the reinforcement of bias, given the
composition of the dataset, underlined the need for clinical expertise
during database construction. Domain knowledge should be exploited to
highlight potential selection bias in the data sample that might
otherwise be subtle. In order to better understand and document
population bias within the sample itself, it would be beneficial to
publish statistics relating to relative populations of the sensitive data
categories contributing to the sample. For example, the relative
proportion of male and female patients, and the relative proportions
of persons in given age ranges, would be useful to identify where the dataset might be biased towards a certain
sex or age demographic.
It would be important to communicate these biases clearly to data
users to ensure an awareness of the limitations of the dataset.\\
 
Although the discussion relating to potential misuse of the data
highlighted the impossibility of identifying every possible future
use, it did raise concerns about the availability of linked data.
The example of using brain-imaging to predict intelligence, and the
sort of damage that might do if applied in such a way as to automate
decision making or to classify individuals, was a powerful one. The
database envisaged for this work would not include information
pertaining to an individual's intelligence, but what information might
it include? This reinforces the idea that it is necessary to carefully
consider and define the data fields made available in the dataset that
is eventually made available to researchers. Consultation with
domain expertise will be vital to determine which fields are most
relevant to the clinical questions to be addressed by the dataset.\\

There was speculation as to what degree the general public expect that
their personal and medical information might be used in research
without their explicit permission. Reviewing ethical research
literature can offer insights in this space, where there have been
studies into how patients feel about what does and doesn't warrant
their explicit consent. In one case where dataset linkage is addressed
specifically~\cite{xafis}, it was noted that most people consulted
felt that data linkage projects without consent are acceptable,
with the condition that researchers do not gain access to identifiable
information. This underlines the importance of having a fully
anonymized dataset for researchers and for data linkage to take place
within the NBT system, and speaks to the necessity for public trust in data
stewards. In this project NBT are the data stewards of the sensitive
data, and the NHS is generally perceived as trustworthy organisation in terms
of information privacy and security.  \\

Even with available ethics literature and historical studies that seek
to understand public views on the processing of their data in a
health-care setting and beyond, the fruitful discussions highlighted
the need for engaging with both the public and care-givers early
throughout the project lifetime. The workshop served as a valuable
consultation with academics and data-centric professionals, and
identified key ethical points to consider and integrate into the
project design and implementation. 


\printbibliography

\end{document}

% notes collected during workshop
%\begin{itemize}
%\item PhD student in environmental economics.
%\item PhD student in mental health data science.
%\item Lecturer, machine translation.
%\item Medical data manager.
%\item Data scientist, Foreign, Commonwealth and Development Office.
%\end{itemize}
%
%
%
%
%\item difficult to eliminate completely any of these hazards, ANYTHING
%  can be misused. If the dataset is available to others then it could
%  be misused.
%
% \subsection{Reinforcing existing biases:}
%
%
%\item Unless you were able to draw on other datasets then not possible to
%protect from biases present in that dataset (e.g. biases on when
%illnesses are reported and how they are reported).
%
%\item How are biases being introduced and how are they being highlighted.
%
%\item Would this be used in other countries even, where the population
%  in this dataset would not be representative of the native
%  population?
%  -- as a part of the project, get summaries about sample population.
%  
%\item having subject-specialist knowledge would be helpful (to
%  understand what any existing biases would be) -- difficult for
%  participants to think about what biases might be in the data, and
%  what might be important for clinical decision making.
%
%  
%\subsection{Danger of misuse}
%
%\item Could you ultimately (in the future) draw sensitive information
%  from a CT scan image? Could they be misused for other purposes?
%
%\item because the range of applications is so broad, you cannot
%  anticipate what it could be used for so you can't anticipate how it
%  might be misused.
%
%\item hard to anticipate what forms of misuse could arise when the
%  dataset goes ``out in the open''. E.g. predict intelligence through
%  CT scan image analysis.
%  --> Kind of reject it, because we don't have linked information
%  on subject's intelligence.
%  --> Strikes me that this simply pushes the necessity to carefully
%  define the data fields made available in the dataset.
%  --> balance to be made: but ``publishing data is
%  dangerous and we shouldn't do it'' because open data is super
%  important.
%
%\subsection{Lack of informed consent}
%\item Do people really understand what is being done with the
%  data?
%  --> public consultation, trust in the data stewards.
%  --> makes considering other hazards even more important.
%
%\item Impracticality of getting informed consent.
%
%\subsection{Lacks community involvement}
%\item Patient consultation is important -- should do this as a part of
%  the study (PPI).  
%\item Patients generally support data use for benefit of society.
%\end{itemize}
